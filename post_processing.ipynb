{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upfront Childcare Provider Scraping Program\n",
    "This notebook outlines the usage of several scripts dedicated to scraping, parsing, transforming, and cleaning of data from New York State, and New York City public websites. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining Data from Office of Childcare and Family Services:\n",
    "---\n",
    "This data is found @ https://ocfs.ny.gov/programs/childcare/looking/ccfs-search.php\n",
    "- We can utilize the main script found in the OCFS directory. This will gather all of the data from the site and prep it for our cleaning. \n",
    "- This can be run with the following command (make sure you have done the steps for correct setup beforehand)\n",
    "- Be aware, this script takes several hours to run so that it does not spam the website servers. (~5 hours as of December 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the OCFS scraping script:\n",
    "!python OCFS/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our result data, which can be found in ```OCFS/result_data/OCFS_result_data.csv```. This data adhears to the Upfront data model for childcare providers, but there are still some cleaning and validation steps we can take to enhance the quality of the data. For this, we can use PETL and a few helper functions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# This is a JSON hash map of the zip codes per county in NYC. \n",
    "with open(\"nyc_zip_to_county.json\", \"r\") as file:\n",
    "    zip_to_county = json.load(file)\n",
    "    zip_to_county[''] = ''\n",
    "\n",
    "# A hash map of the county name to the borough name. \n",
    "county_to_borough = {\n",
    "    \"New York County\": \"Manhattan\",\n",
    "    \"Kings County\": \"Brooklyn\",\n",
    "    \"Queens County\": \"Queens\",\n",
    "    \"Bronx County\": \"The Bronx\",\n",
    "    \"Richmond County\": \"Staten Island\",\n",
    "    \"\" : \"\"\n",
    "}\n",
    "\n",
    "# This function standardizes the format of all phone numbers to (111) 222-3333\n",
    "def standardize_phone_number(phone: str) -> str:\n",
    "    # Extract all digits from the input string\n",
    "    digits = re.sub(r'\\D', '', phone)\n",
    "    \n",
    "    # Validate we have exactly 10 digits\n",
    "    if len(digits) != 10:\n",
    "        raise ValueError(f\"Phone number must contain exactly 10 digits. Got: {len(digits)} digits\")\n",
    "    \n",
    "    # Format the digits into the desired pattern\n",
    "    formatted = f\"({digits[:3]}) {digits[3:6]}-{digits[6:]}\"\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "# This standardizes our faciity names in accordance with Upfronts naming conventions using regular expressions\n",
    "def standardize_facility_name(name: str, street_name: str = \"\") -> str:\n",
    "    name = ''.join(c for c in unicodedata.normalize('NFD', name) if unicodedata.category(c) != 'Mn')\n",
    "    name = re.sub(r'\\b[A-Z]\\b', '', name)\n",
    "    name = name.replace('&', 'and')\n",
    "    name = name.replace('@', 'at')\n",
    "    name = re.sub(r',?\\s*(LLC|Inc|Incorporated)(\\.|$)', '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'\\bYmca\\b', 'YMCA', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'\\b(?:dba|d\\.b\\.a\\.)\\s+', '', name, flags=re.IGNORECASE)\n",
    "    if street_name:\n",
    "        name = f\"{name.strip()} - {street_name.strip()}\"\n",
    "    name = re.sub(r'\\((.*?)\\)', r'- \\1', name)\n",
    "    name = re.sub(r'\\boperated\\b.*$', '', name, flags=re.IGNORECASE).strip()\n",
    "    replacements = {\n",
    "        'Ctr\\.': 'Center',\n",
    "        '\\bRD\\b': 'Road',\n",
    "        '\\bSt\\b': 'Street',\n",
    "        '\\bAVE\\b': 'Avenue',\n",
    "        '\\bDr\\b': 'Drive'\n",
    "    }\n",
    "    for abbrev, full in replacements.items():\n",
    "        name = re.sub(abbrev, full, name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'\\bIi\\b', 'II', name, flags=re.IGNORECASE)\n",
    "    small_words = {'a', 'an', 'the', 'or', 'of', 'and', 'in', 'on', 'at'}\n",
    "    name_parts = name.split()\n",
    "    name = ' '.join(word.lower() if word.lower() in small_words else word for word in name_parts)\n",
    "    name = re.sub(r'\\s*-\\s*', ' - ', name)\n",
    "    name = re.sub(r'#\\d+', '', name)\n",
    "    if street_name:\n",
    "        name = f\"{name.strip()} - {street_name.strip()}\"\n",
    "\n",
    "    return name.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import petl as etl\n",
    "from distutils.util import strtobool\n",
    "\n",
    "# Grab the data from the results, and normalize the data within it\n",
    "OCFS_data = (\n",
    "    etl\n",
    "    .fromcsv(\"OCFS/result_data/OCFS_result_data.csv\")    \n",
    "    .cutout(\"ADDRESS_BOUROUGH\", \"ADDRESS_COUNTY\")\n",
    "    .addfield(\"ADDRESS_COUNTY\", lambda row : zip_to_county.get(row.ADDRESS_ZIPCODE[:5]))\n",
    "    .addfield(\"ADDRESS_BOUROUGH\", lambda row : county_to_borough.get(row.ADDRESS_COUNTY))\n",
    "    .addfield(\"AGE_INFANT_MINIMUM\", lambda row : \"6 Weeks\" if bool(strtobool(row.AGE_RANGE_INFANTS)) == True else \"\")\n",
    "    .convert(\"PROGRAM_NAME\", lambda v : standardize_facility_name(v))\n",
    "    .convert(\"GEN_PHONE_1\", lambda v : standardize_phone_number(v))\n",
    "    .convert(\"ADDRESS_CITY\", lambda v : \"New York City\")\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes in the data, we have duplicate program names due to the fact that a program might have several locations. If this is the case, we want to add the address location to the name of the program to distinguish it from the other locations. We can do this using a list of duplicate program names and PETL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grab a list of duplicate program names \n",
    "OCFS_duplicate_names = list(OCFS_data.duplicates('PROGRAM_NAME').values(\"PROGRAM_NAME\"))\n",
    "\n",
    "# Change any of the duplicate names so that the program name has the address appended to it if there are more than one location\n",
    "OCFS_data_deduped = (\n",
    "    OCFS_data\n",
    "    .addfield(\"FIXED_PROGRAM_NAME\", lambda row : row.PROGRAM_NAME if not row.PROGRAM_NAME in OCFS_duplicate_names else f\"{row.PROGRAM_NAME} - {row.ADDRESS_STREET}\")\n",
    "    .cutout(\"PROGRAM_NAME\")\n",
    "    .rename(\"FIXED_PROGRAM_NAME\", \"PROGRAM_NAME\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining Data from New York City Health:\n",
    "---\n",
    "This data is found @ https://a816-healthpsi.nyc.gov/ChildCare/search.action\n",
    "- Again, we can utlize our main script for the NYCH directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the NYCH scraping script:\n",
    "!python NYCH/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the result data for the NCYH site that can be found at ```NYCH/result_data/NYCH_result_data.csv```. This data is also in the Upfront format, and we can also standardize and deduplicate it as we did with the OCFS data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYCH_data = (\n",
    "    etl\n",
    "    .fromcsv(\"NYCH/result_data/NYCH_result_data.csv\")\n",
    "    .convert(\"GEN_WEBSITE\", lambda rec : \"https://a816-healthpsi.nyc.gov/ChildCare/search\") # Hard code this due to it being the same for every record\n",
    "    .convert(\"ADDRESS_ZIPCODE\", lambda v : v.strip())    \n",
    "    .cutout(\"ADDRESS_BOUROUGH\", \"ADDRESS_COUNTY\", \"AGE_INFANT_MINIMUM\")\n",
    "    .addfield(\"ADDRESS_COUNTY\", lambda row : zip_to_county.get(row.ADDRESS_ZIPCODE[:5]))\n",
    "    .addfield(\"ADDRESS_BOUROUGH\", lambda row : county_to_borough.get(row.ADDRESS_COUNTY))\n",
    "    .addfield(\"AGE_INFANT_MINIMUM\", lambda row : \"0 Weeks\" if bool(strtobool(row.AGE_RANGE_INFANTS)) == True else \"\") # Make sure to standarzie on a 0 week minimum if it is in the infant age range\n",
    "    .convert(\"PROGRAM_NAME\", lambda v : standardize_facility_name(v))\n",
    "    .convert(\"GEN_PHONE_1\", lambda v : standardize_phone_number(v))\n",
    "    .convert(\"ADDRESS_CITY\", lambda v : \"New York City\")\n",
    "    )\n",
    "\n",
    "NYCH_duplicate_names = list(NYCH_data.duplicates('PROGRAM_NAME').values(\"PROGRAM_NAME\"))\n",
    "\n",
    "NYCH_data_deduped = (\n",
    "    NYCH_data\n",
    "    .addfield(\"FIXED_PROGRAM_NAME\", lambda row : row.PROGRAM_NAME if not row.PROGRAM_NAME in NYCH_duplicate_names else f\"{row.PROGRAM_NAME} - {row.ADDRESS_STREET}\")\n",
    "    .cutout(\"PROGRAM_NAME\")\n",
    "    .rename(\"FIXED_PROGRAM_NAME\", \"PROGRAM_NAME\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Final Dataset:\n",
    "--- \n",
    "Now that we have all of our data from both OCFS and NYCH, we can combine the data to get our final dataset of all the available data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully gathered 2704 result records!\n"
     ]
    }
   ],
   "source": [
    "# Re-order the columns:\n",
    "column_order = [\n",
    "    \"PROGRAM_NAME\", \"ADDRESS_CITY\", \"ADDRESS_COUNTRY\", \"ADDRESS_BOUROUGH\", \n",
    "    \"ADDRESS_COUNTY\", \"ADDRESS_LATITUDE\", \"ADDRESS_LONGITUDE\", \"ADDRESS_STATE\", \n",
    "    \"ADDRESS_STREET\", \"ADDRESS_ZIPCODE\", \"AGE_INFANT_MINIMUM\", \"AGE_RANGE\", \n",
    "    \"AGE_RANGE_1_YEAR\", \"AGE_RANGE_2_YEARS\", \"AGE_RANGE_3_YEARS\", \n",
    "    \"AGE_RANGE_4_YEARS\", \"AGE_RANGE_5_YEARS\", \"AGE_RANGE_INFANTS\", \n",
    "    \"AGE_RANGE_SCHOOL\", \"GEN_PHONE_1\", \"GEN_PROGRAM_SETTING\", \"GEN_WEBSITE\"\n",
    "]\n",
    "\n",
    "# Reorder columns for OCFS_data_deduped\n",
    "OCFS_data_final = OCFS_data_deduped.cut(*column_order)\n",
    "\n",
    "# Reorder columns for NYCH_data_deduped\n",
    "NYCH_data_final = NYCH_data_deduped.cut(*column_order)\n",
    "\n",
    "# Combine both datasets\n",
    "ALL_results = etl.cat(OCFS_data_final, NYCH_data_final)\n",
    "\n",
    "# Print the length of all of the result to see how many records we gathered\n",
    "print(f\"Successfully gathered {len(ALL_results)} result records!\")\n",
    "\n",
    "# Save the result CSV:\n",
    "ALL_results.tocsv(\"results_final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
